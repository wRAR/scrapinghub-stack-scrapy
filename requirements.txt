#
# This file is autogenerated by pip-compile with Python 3.10
# by the following command:
#
#    pip-compile --output-file=requirements.txt requirements.in
#
aiohttp==3.8.3
    # via -r requirements.in
aiosignal==1.3.1
    # via aiohttp
arrow==1.2.3
    # via isoduration
async-timeout==4.0.2
    # via aiohttp
attrs==22.2.0
    # via
    #   aiohttp
    #   automat
    #   jsonschema
    #   service-identity
    #   twisted
automat==22.10.0
    # via twisted
awscli==1.27.62
    # via
    #   -r requirements.in
    #   scrapy-dotpersistence
boto==2.49.0
    # via
    #   -r requirements.in
    #   spidermon
boto3==1.26.62
    # via
    #   -r requirements.in
    #   spidermon
botocore==1.29.62
    # via
    #   awscli
    #   boto3
    #   s3transfer
cachetools==5.3.0
    # via premailer
certifi==2022.12.7
    # via
    #   requests
    #   sentry-sdk
cffi==1.15.1
    # via cryptography
charset-normalizer==2.1.1
    # via
    #   aiohttp
    #   requests
colorama==0.4.4
    # via awscli
constantly==15.1.0
    # via twisted
cryptography==39.0.0
    # via
    #   -r requirements.in
    #   pyopenssl
    #   scrapy
    #   service-identity
cssselect==1.2.0
    # via
    #   parsel
    #   premailer
    #   scrapy
cssutils==2.6.0
    # via premailer
docutils==0.16
    # via awscli
filelock==3.9.0
    # via tldextract
fqdn==1.5.1
    # via jsonschema
frozenlist==1.3.3
    # via
    #   aiohttp
    #   aiosignal
h2==4.1.0
    # via twisted
hpack==4.0.0
    # via h2
hyperframe==6.0.1
    # via h2
hyperlink==21.0.0
    # via twisted
idna==3.4
    # via
    #   hyperlink
    #   jsonschema
    #   requests
    #   tldextract
    #   yarl
incremental==22.10.0
    # via twisted
isoduration==20.11.0
    # via jsonschema
itemadapter==0.7.0
    # via
    #   itemloaders
    #   scrapy
itemloaders==1.0.6
    # via scrapy
jinja2==3.1.2
    # via
    #   -r requirements.in
    #   spidermon
jmespath==1.0.1
    # via
    #   boto3
    #   botocore
    #   itemloaders
jsonpointer==2.3
    # via jsonschema
jsonschema[format]==4.17.3
    # via spidermon
lxml==4.9.2
    # via
    #   -r requirements.in
    #   parsel
    #   premailer
    #   scrapy
markupsafe==2.1.2
    # via jinja2
monkeylearn==3.6.0
    # via -r requirements.in
multidict==6.0.4
    # via
    #   aiohttp
    #   yarl
packaging==23.0
    # via
    #   parsel
    #   scrapy
parsel==1.7.0
    # via
    #   itemloaders
    #   scrapy
pillow==9.4.0
    # via -r requirements.in
premailer==3.10.0
    # via spidermon
priority==1.3.0
    # via twisted
protego==0.2.1
    # via scrapy
pyasn1==0.4.8
    # via
    #   pyasn1-modules
    #   rsa
    #   service-identity
pyasn1-modules==0.2.8
    # via service-identity
pycparser==2.21
    # via cffi
pydispatcher==2.0.6
    # via scrapy
pyopenssl==23.0.0
    # via scrapy
pyrsistent==0.19.3
    # via jsonschema
python-dateutil==2.8.2
    # via
    #   arrow
    #   botocore
python-slugify==8.0.0
    # via spidermon
pyyaml==5.4.1
    # via
    #   -r requirements.in
    #   awscli
queuelib==1.6.2
    # via scrapy
requests==2.28.2
    # via
    #   -r requirements.in
    #   monkeylearn
    #   premailer
    #   requests-file
    #   scrapinghub
    #   tldextract
requests-file==1.5.1
    # via tldextract
retrying==1.3.4
    # via scrapinghub
rfc3339-validator==0.1.4
    # via jsonschema
rfc3987==1.3.8
    # via jsonschema
rsa==4.7.2
    # via awscli
s3transfer==0.6.0
    # via
    #   awscli
    #   boto3
schematics==2.1.1
    # via spidermon
scrapinghub==2.4.0
    # via
    #   -r requirements.in
    #   scrapinghub-entrypoint-scrapy
    #   scrapy-pagestorage
    #   spidermon
scrapinghub-entrypoint-scrapy==0.14.0
    # via
    #   -r requirements.in
    #   scrapy-pagestorage
scrapy==2.8.0
    # via
    #   -r requirements.in
    #   scrapinghub-entrypoint-scrapy
    #   scrapy-crawlera
    #   scrapy-deltafetch
    #   scrapy-dotpersistence
    #   scrapy-magicfields
    #   scrapy-pagestorage
    #   scrapy-querycleaner
    #   scrapy-splitvariants
    #   scrapy-zyte-smartproxy
    #   spidermon
scrapy-crawlera==1.7.2
    # via -r requirements.in
scrapy-deltafetch==2.0.1
    # via -r requirements.in
scrapy-dotpersistence==0.3.0
    # via -r requirements.in
scrapy-magicfields==1.1.0
    # via -r requirements.in
scrapy-pagestorage==0.4.0
    # via -r requirements.in
scrapy-querycleaner==1.0.0
    # via -r requirements.in
scrapy-splash==0.8.0
    # via -r requirements.in
scrapy-splitvariants==1.1.0
    # via -r requirements.in
scrapy-zyte-smartproxy==2.2.0
    # via -r requirements.in
sentry-sdk==1.14.0
    # via spidermon
service-identity==21.1.0
    # via scrapy
six==1.16.0
    # via
    #   automat
    #   monkeylearn
    #   protego
    #   python-dateutil
    #   requests-file
    #   retrying
    #   rfc3339-validator
    #   scrapinghub
    #   scrapy-crawlera
    #   scrapy-querycleaner
    #   scrapy-zyte-smartproxy
    #   service-identity
slack-sdk==3.19.5
    # via spidermon
spidermon[monitoring,validation]==1.17.1
    # via -r requirements.in
text-unidecode==1.3
    # via python-slugify
tldextract==3.4.0
    # via scrapy
twisted[http2]==22.10.0
    # via
    #   -r requirements.in
    #   scrapy
typing-extensions==4.4.0
    # via twisted
uri-template==1.2.0
    # via jsonschema
urllib3==1.26.14
    # via
    #   -r requirements.in
    #   botocore
    #   requests
    #   sentry-sdk
w3lib==2.1.1
    # via
    #   itemloaders
    #   parsel
    #   scrapy
    #   scrapy-crawlera
    #   scrapy-zyte-smartproxy
webcolors==1.12
    # via jsonschema
yarl==1.8.2
    # via aiohttp
zope-interface==5.5.2
    # via
    #   scrapy
    #   twisted

# The following packages are considered to be unsafe in a requirements file:
# setuptools
