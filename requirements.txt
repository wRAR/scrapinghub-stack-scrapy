#
# This file is autogenerated by pip-compile with Python 3.12
# by the following command:
#
#    pip-compile --output-file=requirements.txt requirements.in
#
aiohappyeyeballs==2.4.3
    # via aiohttp
aiohttp==3.11.2
    # via -r requirements.in
aiosignal==1.3.1
    # via aiohttp
arrow==1.3.0
    # via isoduration
attrs==24.2.0
    # via
    #   aiohttp
    #   jsonschema
    #   referencing
    #   service-identity
    #   twisted
automat==24.8.1
    # via twisted
awscli==1.36.4
    # via
    #   -r requirements.in
    #   scrapy-dotpersistence
boto==2.49.0
    # via
    #   -r requirements.in
    #   spidermon
boto3==1.35.63
    # via
    #   -r requirements.in
    #   spidermon
botocore==1.35.63
    # via
    #   awscli
    #   boto3
    #   s3transfer
cachetools==5.5.0
    # via premailer
certifi==2024.8.30
    # via
    #   requests
    #   sentry-sdk
cffi==1.17.1
    # via cryptography
charset-normalizer==3.4.0
    # via requests
colorama==0.4.6
    # via awscli
constantly==23.10.4
    # via twisted
cryptography==43.0.3
    # via
    #   pyopenssl
    #   scrapy
    #   service-identity
cssselect==1.2.0
    # via
    #   parsel
    #   premailer
    #   scrapy
cssutils==2.11.1
    # via premailer
defusedxml==0.7.1
    # via scrapy
docutils==0.16
    # via awscli
filelock==3.16.1
    # via tldextract
fqdn==1.5.1
    # via jsonschema
frozenlist==1.5.0
    # via
    #   aiohttp
    #   aiosignal
h2==4.1.0
    # via twisted
hpack==4.0.0
    # via h2
hyperframe==6.0.1
    # via h2
hyperlink==21.0.0
    # via twisted
idna==3.10
    # via
    #   hyperlink
    #   jsonschema
    #   requests
    #   tldextract
    #   yarl
incremental==24.7.2
    # via twisted
isoduration==20.11.0
    # via jsonschema
itemadapter==0.9.0
    # via
    #   itemloaders
    #   scrapy
    #   spidermon
itemloaders==1.3.2
    # via scrapy
jinja2==3.1.4
    # via
    #   -r requirements.in
    #   spidermon
jmespath==1.0.1
    # via
    #   boto3
    #   botocore
    #   itemloaders
    #   parsel
jsonpointer==3.0.0
    # via jsonschema
jsonschema[format]==4.23.0
    # via spidermon
jsonschema-specifications==2024.10.1
    # via jsonschema
lxml==5.3.0
    # via
    #   -r requirements.in
    #   parsel
    #   premailer
    #   scrapy
markupsafe==3.0.2
    # via jinja2
monkeylearn==3.6.0
    # via -r requirements.in
more-itertools==10.5.0
    # via cssutils
multidict==6.1.0
    # via
    #   aiohttp
    #   yarl
packaging==24.2
    # via
    #   parsel
    #   scrapy
parsel==1.9.1
    # via
    #   itemloaders
    #   scrapy
pillow==11.0.0
    # via -r requirements.in
premailer==3.10.0
    # via spidermon
priority==1.3.0
    # via twisted
propcache==0.2.0
    # via
    #   aiohttp
    #   yarl
protego==0.3.1
    # via scrapy
pyasn1==0.6.1
    # via
    #   pyasn1-modules
    #   rsa
    #   service-identity
pyasn1-modules==0.4.1
    # via service-identity
pycparser==2.22
    # via cffi
pydispatcher==2.0.7
    # via scrapy
pyopenssl==24.2.1
    # via scrapy
python-dateutil==2.9.0.post0
    # via
    #   arrow
    #   botocore
python-slugify==8.0.4
    # via spidermon
pyyaml==6.0.2
    # via
    #   -r requirements.in
    #   awscli
queuelib==1.7.0
    # via scrapy
referencing==0.35.1
    # via
    #   jsonschema
    #   jsonschema-specifications
requests==2.32.3
    # via
    #   -r requirements.in
    #   monkeylearn
    #   premailer
    #   requests-file
    #   scrapinghub
    #   spidermon
    #   tldextract
requests-file==2.1.0
    # via tldextract
retrying==1.3.4
    # via scrapinghub
rfc3339-validator==0.1.4
    # via jsonschema
rfc3987==1.3.8
    # via jsonschema
rpds-py==0.21.0
    # via
    #   jsonschema
    #   referencing
rsa==4.7.2
    # via awscli
s3transfer==0.10.3
    # via
    #   awscli
    #   boto3
scrapinghub==2.4.0
    # via
    #   -r requirements.in
    #   scrapinghub-entrypoint-scrapy
    #   scrapy-pagestorage
    #   spidermon
scrapinghub-entrypoint-scrapy==0.17.4
    # via
    #   -r requirements.in
    #   scrapy-pagestorage
    #   spidermon
scrapy==2.12.0
    # via
    #   -r requirements.in
    #   scrapinghub-entrypoint-scrapy
    #   scrapy-crawlera
    #   scrapy-deltafetch
    #   scrapy-dotpersistence
    #   scrapy-magicfields
    #   scrapy-pagestorage
    #   scrapy-querycleaner
    #   scrapy-splitvariants
    #   scrapy-zyte-smartproxy
    #   spidermon
scrapy-crawlera==1.7.2
    # via -r requirements.in
scrapy-deltafetch==2.0.1
    # via -r requirements.in
scrapy-dotpersistence==0.3.0
    # via -r requirements.in
scrapy-magicfields==1.1.0
    # via -r requirements.in
scrapy-pagestorage==0.4.0
    # via -r requirements.in
scrapy-querycleaner==1.0.0
    # via -r requirements.in
scrapy-splash==0.9.0
    # via -r requirements.in
scrapy-splitvariants==1.1.0
    # via -r requirements.in
scrapy-zyte-smartproxy==2.3.5
    # via -r requirements.in
sentry-sdk==2.18.0
    # via spidermon
service-identity==24.2.0
    # via scrapy
six==1.16.0
    # via
    #   monkeylearn
    #   python-dateutil
    #   retrying
    #   rfc3339-validator
    #   scrapinghub
    #   scrapy-crawlera
    #   scrapy-querycleaner
    #   scrapy-zyte-smartproxy
slack-sdk==3.33.3
    # via spidermon
spidermon[monitoring]==1.23.0
    # via -r requirements.in
text-unidecode==1.3
    # via python-slugify
tldextract==5.1.3
    # via scrapy
twisted[http2]==24.10.0
    # via
    #   -r requirements.in
    #   scrapy
    #   twisted
types-python-dateutil==2.9.0.20241003
    # via arrow
typing-extensions==4.12.2
    # via twisted
uri-template==1.3.0
    # via jsonschema
urllib3==2.2.3
    # via
    #   -r requirements.in
    #   botocore
    #   requests
    #   sentry-sdk
w3lib==2.2.1
    # via
    #   parsel
    #   scrapy
    #   scrapy-crawlera
    #   scrapy-zyte-smartproxy
webcolors==24.11.1
    # via jsonschema
yarl==1.17.2
    # via aiohttp
zope-interface==7.1.1
    # via
    #   scrapy
    #   twisted

# The following packages are considered to be unsafe in a requirements file:
# setuptools
